{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Stream (and Cleaning Tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get your own consumer key, consumer secret, access token and access secret, create a Twitter application: https://apps.twitter.com/app/new."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. One way of doing it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import (Stream, OAuthHandler) # OAuth is an open standard for access delegation, commonly used as a way for Internet users to grant websites or applications access to their information on other websites but without giving them the passwords.\n",
    "from tweepy.streaming import StreamListener\n",
    "import time # For time.sleep()\n",
    "\n",
    "C_KEY = 'idOmzXJyleGlgKDwAyy8bMaR5' # Consumer key\n",
    "C_SECRET = 'hBLq9264HFWs82xdQBn9lEsaPQNBvPyIs82yvG2roefS2IZLnZ'\n",
    "A_TOKEN = '3071337529-W7L2ghMe81qn67n7rvq3Q8eVblgS3YbjmGJjyBG' # Access token\n",
    "A_SECRET = 'KVuB7RedBB0byVE8OASILCg7yu8nwx12uNnnxi3WVBTMZ'\n",
    "\n",
    "class Listener(StreamListener):\n",
    "    def on_status(self, status): # on_data() would print a lot more detailed data. on_status() focuses on status updates.\n",
    "        try:\n",
    "            save_file = open('twitDB.txt', 'a', encoding='utf-8') # a = append\n",
    "            save_file.write(str(time.time()) + ':: ' + status.text.replace('\\n', ' '))\n",
    "            save_file.write('\\n')\n",
    "            save_file.close()\n",
    "            return True\n",
    "        except BaseException as err: # BaseException is the base class for all built-in exceptions. Problems that could happen are connection issues.\n",
    "            print('Failed on_status, ', str(err))\n",
    "            time.sleep(5)\n",
    "    \n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "        \n",
    "auth  = OAuthHandler(C_KEY, C_SECRET) # Authorizing ourselves\n",
    "auth.set_access_token(A_TOKEN, A_SECRET)\n",
    "twitter_stream = Stream(auth, Listener())\n",
    "twitter_stream.filter(track='car') # Filtering tweets. Possible params: locations, languages, follow (people). The default argument for all of these is None. NB very few accounts have geolocations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Another way of doing it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Screen name = \"matthewloop\" Tweet = \"How to Create a Facebook Ad That Works With WhatsApp Business https://t.co/SyxaqIrpyG via @markekodigital\"\n",
      "2. Screen name = \"ProphetSimuelJr\" Tweet = \"YOU'RE INVITED.. \" Jarrett Burton and praise \" 4.6.18  Kingdom Grace and FAITH CONFERENCE‚Ä¶ https://t.co/BUwMtvO3xO\"\n",
      "3. Screen name = \"SparkyTeach\" Tweet = \"@APSCCES Parents explaining how to support students at home! Awesome!!! üëèüèæüëèüèæüëèüèæ@zackoryk https://t.co/nLGb4SVWcW\"\n",
      "4. Screen name = \"KingxShe\" Tweet = \"@kadariusharper4 DM me your number\"\n",
      "5. Screen name = \"Jbonee_74\" Tweet = \"This Excludes Gordon I Got Dumb Love For The G-Townüñ§\"\n",
      "6. Screen name = \"purp_herbstreit\" Tweet = \"I took them Xannies on Earth...woke up right there on Mars\"\n",
      "7. Screen name = \"K2xXB\" Tweet = \"@TdotMark @bomani_jones Thanks for pointing that out mark.  Join @tdotnark and @nomani_jones your future hero me as‚Ä¶ https://t.co/W0151Q1EsF\"\n",
      "8. Screen name = \"EncoreAtlanta\" Tweet = \"This #BestBet is for our Francophiles. Il Etait Une Fois (Once Upon a Time), a world premiere‚Ä¶ https://t.co/bW1I845CH4\"\n",
      "9. Screen name = \"Gabriel99506994\" Tweet = \"@aniyamartinez2 @BhadBhabie Gabriela yes girls Gabriela\"\n",
      "10. Screen name = \"kingdaley__\" Tweet = \"Cod been disappointing since Advanded Warfare https://t.co/G4gRqT4KdS\"\n",
      "11. Screen name = \"GoooodasFiDem\" Tweet = \"@keilograms Lmao I won‚Äôt girl free face beats for life!!!! üíÅüèΩ\"\n",
      "12. Screen name = \"TheEliteSoulGod\" Tweet = \"I know that days may get sad, I get mad, and act like a complete ass. But-you are stuck in my mind like quick sand.‚Ä¶ https://t.co/QHQDeahFJE\"\n",
      "13. Screen name = \"DajLoafff\" Tweet = \"Happy Bday baby!!! You are beautiful, enjoy your day üòò https://t.co/rluBPkNVLZ\"\n",
      "14. Screen name = \"CutiePatooty94\" Tweet = \"@HOTmess_DOTcom K. I think I changed it!\"\n",
      "15. Screen name = \"vashston\" Tweet = \"this is so fucking cute. https://t.co/vkifumuW0I\"\n",
      "16. Screen name = \"aps_papac\" Tweet = \"Get it Dr. ‚ÄúV‚Äù!  We üëÄ u! https://t.co/17iirWoL04\"\n",
      "17. Screen name = \"selftitledjaci\" Tweet = \"OOOOO SO R U https://t.co/D0N7uicV1f\"\n",
      "18. Screen name = \"berggrenholly\" Tweet = \"@rickygervais Older article but interesting and goes into some detail https://t.co/d4IBsM31aY\"\n",
      "19. Screen name = \"sup_cathy\" Tweet = \"üòä https://t.co/AdsQqLnrDM\"\n",
      "20. Screen name = \"AmyBoland37\" Tweet = \"Excited to get into some holy mischief and see my friends who are like family, in a city I love‚Ä¶ https://t.co/rzIJZKZ3N8\"\n",
      "Max num reached = 20\n"
     ]
    }
   ],
   "source": [
    "from tweepy import (Stream, OAuthHandler)\n",
    "from tweepy.streaming import StreamListener\n",
    " \n",
    "class Listener(StreamListener):\n",
    "\n",
    "    tweet_counter = 0 # Static variable\n",
    "    \n",
    "    def login(self):\n",
    "        CONSUMER_KEY = 'idOmzXJyleGlgKDwAyy8bMaR5'\n",
    "        CONSUMER_SECRET = 'hBLq9264HFWs82xdQBn9lEsaPQNBvPyIs82yvG2roefS2IZLnZ'\n",
    "        ACCESS_TOKEN = '3071337529-W7L2ghMe81qn67n7rvq3Q8eVblgS3YbjmGJjyBG'\n",
    "        ACCESS_TOKEN_SECRET = 'INSERT_YOUR_OWN_HERE'\n",
    "\n",
    "        auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "        auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "        return auth\n",
    "    \n",
    "    def on_status(self, status):\n",
    "        Listener.tweet_counter += 1\n",
    "        print(str(Listener.tweet_counter) + '. Screen name = \"%s\" Tweet = \"%s\"'\n",
    "              %(status.author.screen_name, status.text.replace('\\n', ' ')))\n",
    "\n",
    "        if Listener.tweet_counter < Listener.stop_at:\n",
    "            return True\n",
    "        else:\n",
    "            print('Max num reached = ' + str(Listener.tweet_counter))\n",
    "            return False\n",
    "\n",
    "    def getTweetsByGPS(self, stop_at_number, latitude_start, longitude_start, latitude_finish, longitude_finish):\n",
    "        try:\n",
    "            Listener.stop_at = stop_at_number # Create static variable\n",
    "            auth = self.login()\n",
    "            streaming_api = Stream(auth, Listener(), timeout=60) # Socket timeout value\n",
    "            streaming_api.filter(follow=None, locations=[latitude_start, longitude_start, latitude_finish, longitude_finish])\n",
    "        except KeyboardInterrupt:\n",
    "            print('Got keyboard interrupt')\n",
    "\n",
    "    def getTweetsByHashtag(self, stop_at_number, hashtag):\n",
    "        try:\n",
    "            Listener.stopAt = stop_at_number\n",
    "            auth = self.login()\n",
    "            streaming_api = Stream(auth, Listener(), timeout=60)\n",
    "            # Atlanta area.\n",
    "            streaming_api.filter(track=[hashtag])\n",
    "        except KeyboardInterrupt:\n",
    "            print('Got keyboard interrupt')\n",
    "\n",
    "listener = Listener()\n",
    "listener.getTweetsByGPS(20, -84.395198, 33.746876, -84.385585, 33.841601) # Atlanta area. Tool to find coordinates for any place: http://boundingbox.klokantech.com/ (use CSV as the output format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cleaning tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tweet:     RT @Amila #Test\n",
      "Tom's newly listed Co. &amp; Mary's unlisted     Group to supply tech for nlTK.\n",
      "h.. $TSLA $AAPL https:// t.co/x34afsfQsh \n",
      "\n",
      "No special entitites:     RT @Amila #Test\n",
      "Tom's newly listed Co.  Mary's unlisted     Group to supply tech for nlTK.\n",
      "h.. $TSLA $AAPL https:// t.co/x34afsfQsh \n",
      "\n",
      "No tickers:     RT @Amila #Test\n",
      "Tom's newly listed Co.  Mary's unlisted     Group to supply tech for nlTK.\n",
      "h..   https:// t.co/x34afsfQsh \n",
      "\n",
      "No hyperlinks:     RT @Amila #Test\n",
      "Tom's newly listed Co.  Mary's unlisted     Group to supply tech for nlTK.\n",
      "h..    \n",
      "\n",
      "No hashtags:     RT @Amila \n",
      "Tom's newly listed Co.  Mary's unlisted     Group to supply tech for nlTK.\n",
      "h..    \n",
      "\n",
      "No punctuation:     RT @Amila \n",
      "Tom s newly listed Co   Mary s unlisted     Group to supply tech for nlTK \n",
      "h     \n",
      "\n",
      "No small words:      @Amila \n",
      "Tom  newly listed    Mary  unlisted     Group  supply tech for nlTK \n",
      "     \n",
      "\n",
      "No whitespace: @Amila Tom newly listed Mary unlisted Group supply tech for nlTK  \n",
      "\n",
      "No emojis: @Amila Tom newly listed Mary unlisted Group supply tech for nlTK  \n",
      "\n",
      "Tweet tokenize: ['tom', 'newly', 'listed', 'mary', 'unlisted', 'group', 'supply', 'tech', 'for', 'nltk'] \n",
      "\n",
      "No stop words: ['tom', 'newly', 'listed', 'mary', 'unlisted', 'group', 'supply', 'tech', 'nltk'] \n",
      "\n",
      "Final tweet: tom newly listed mary unlisted group supply tech nltk\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "punctuation += '¬¥ŒÑ‚Äô‚Ä¶‚Äú‚Äù‚Äì‚Äî‚Äï¬ª¬´' # string.punctuation misses these.\n",
    "\n",
    "cache_english_stopwords = stopwords.words('english') # Could speed up code by making this a set\n",
    "\n",
    "def tweet_clean(tweet):\n",
    "    print('Original tweet:', tweet, '\\n')\n",
    "    # Remove HTML special entities (e.g. &amp;)\n",
    "    tweet_no_special_entities = re.sub(r'\\&\\w*;', '', tweet)\n",
    "    print('No special entitites:', tweet_no_special_entities, '\\n')\n",
    "    # Remove tickers (Clickable stock market symbols that work like hashtags and start with dollar signs instead)\n",
    "    tweet_no_tickers = re.sub(r'\\$\\w*', '', tweet_no_special_entities) # Substitute. $ needs to be escaped because it means something in regex. \\w means alphanumeric char or underscore.\n",
    "    print('No tickers:', tweet_no_tickers, '\\n')\n",
    "    # Remove hyperlinks\n",
    "    tweet_no_hyperlinks = re.sub(r'https?:\\/\\/.*\\/\\w*', '', tweet_no_tickers)\n",
    "    print('No hyperlinks:', tweet_no_hyperlinks, '\\n')\n",
    "    # Remove hashtags\n",
    "    tweet_no_hashtags = re.sub(r'#\\w*', '', tweet_no_hyperlinks)\n",
    "    print('No hashtags:', tweet_no_hashtags, '\\n')\n",
    "    # Remove Punctuation and split 's, 't, 've with a space for filter\n",
    "    tweet_no_punctuation = re.sub(r'[' + punctuation.replace('@', '') + ']+', ' ', tweet_no_hashtags)\n",
    "    print('No punctuation:', tweet_no_punctuation, '\\n')\n",
    "    # Remove words with 2 or fewer letters (Also takes care of RT)\n",
    "    tweet_no_small_words = re.sub(r'\\b\\w{1,2}\\b', '', tweet_no_punctuation) # \\b represents a word boundary\n",
    "    print('No small words:', tweet_no_small_words, '\\n')\n",
    "    # Remove whitespace (including new line characters)\n",
    "    tweet_no_whitespace = re.sub(r'\\s\\s+', ' ', tweet_no_small_words)\n",
    "    tweet_no_whitespace = tweet_no_whitespace.lstrip(' ') # Remove single space left on the left\n",
    "    print('No whitespace:', tweet_no_whitespace, '\\n')\n",
    "    # Remove characters beyond Basic Multilingual Plane (BMP) of Unicode:\n",
    "    tweet_no_emojis = ''.join(c for c in tweet_no_whitespace if c <= '\\uFFFF') # Apart from emojis (plane 1), this also removes historic scripts and mathematical alphanumerics (also plane 1), ideographs (plane 2) and more.\n",
    "    print('No emojis:', tweet_no_emojis, '\\n')\n",
    "    # Tokenize: Change to lowercase, reduce length and remove handles\n",
    "    tknzr = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True) # reduce_len changes, for example, waaaaaayyyy to waaayyy.\n",
    "    tw_list = tknzr.tokenize(tweet_no_emojis)\n",
    "    print('Tweet tokenize:', tw_list, '\\n')\n",
    "    # Remove stopwords\n",
    "    list_no_stopwords = [i for i in tw_list if i not in cache_english_stopwords]\n",
    "    print('No stop words:', list_no_stopwords, '\\n')\n",
    "    # Final filtered tweet\n",
    "    tweet_filtered =' '.join(list_no_stopwords) # ''.join() would join without spaces between words.\n",
    "    print('Final tweet:', tweet_filtered)\n",
    "\n",
    "s = '    RT @Amila #Test\\nTom\\'s newly listed Co. &amp; Mary\\'s unlisted     Group to supply tech for nlTK.\\nh.. $TSLA $AAPL https:// t.co/x34afsfQsh'\n",
    "tweet_clean(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
